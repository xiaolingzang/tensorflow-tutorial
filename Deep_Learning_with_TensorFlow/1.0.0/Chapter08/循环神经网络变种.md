循环神经网络变种
------------
## 1.双向神经网络
  双向神经网络的主体结构就是两个单向单向循环神经网络的结合。在每一个时刻t,输入会同时提供给这两个方向的循环神经网络，而输出则是  
  由这两个单向循环神经网络共同决定。
  
## 2.深度循环神经网络
  为了增强模型的表达能力，可以将每个时刻的循环体重复多次。和卷积网类似，每一层的循环体中的参数是一致的，而不同层的参数可以不同。  
### deepRNN前向传播过程
```
#定义一个基本的LSTM结构作为循环体的基础结构
lstm=rnn_cell.BasicLSTMCell(lstm_size)
stacked_lstm=rnn_cell.MultiRNNCell([lstm]*number_of_layers)
state=stacked_lstm=.zeros_state(batch_size,tf.float32)

for i in range(num_steps):
    if i>0: tf.get_variable_scope().reuse_variables()
    
    stacked_lstm_output,state=stacked_lstm(current_input,state)
    final_output=fully_connected(lstm_output)
    loss +=calc_loss(final_output,expected_output)
```
## 3.循环神经网络中的dropout
  循环神经网络一般只在不同的层循环体结构之间使用dropout,而不在同一层的循环体结构之间使用。也就是说从t-1到时刻t,循环神经网络不会  
  进行状态的dropout,而在同一时刻t中，不同的循环体之间会使用dropout.
### 带dropout的循环伸经网络
```
lstm=rnn_cell.BasicLSTMCell(lstm_size)
#使用DropoutWrapper类来实现dropout功能，该类通过两个参数控制dropout的概率，一个是input_keep_prob,用来控制输入的dropout概率，  
另一个是output_keep_prob,它可以用来控制输出的dropout概率。  
dropout_lstm=tf.nn.rnn_cell.DropoutWrapper(lstm,output_keep_prob=0.5)
#在使用drop的基础上定义
stacked_lstm=rnn_cell.MultiRNNCell([dropout_lstm]*number_of_layers)
```


