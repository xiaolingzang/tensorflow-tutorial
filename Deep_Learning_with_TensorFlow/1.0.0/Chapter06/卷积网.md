
### tensorflow 实现卷积网的基本函数
1.通过tf.get_varibale的方式创建过滤器的权重和偏置项变量  
卷积层的参数个数只和过滤器的尺寸、深度、以及当前层节点矩阵的深度有关，所以声明的参数变量是一个四维矩阵，前面两个维度代表了过滤器的尺寸，第三个维度代表了当前层的深度，第四个维度表示过滤器的深度。
```
filter_weigth=tf.get_variable('weigth',[5,5,3,16],initializer=tf.constant_initializer(0.1))
```  
和卷积权重类似，当前层上不同位置上的偏置项也是共享的，所以共有一下层深度的不同个偏置项。
```
biases=tf.get_varibale('biases',[16],initializer=tf.constant_initializer(0.1)
```
2.卷积过程  
tf.nn.conv2d提供了一个非常方便的函数用来实现卷积神经网络的前向传播算法.  
这个函数的第一个输入为当前层节点矩阵，这个矩阵是一个四维矩阵，后面三个维度对应一个节点矩阵，第一维对应一个输入batch；  
这个函数的第二个参数对应卷积权重；
第三个参数为不同维度上的步长。虽然第三个参数提供了一个长度为4的数组，但是第一维和最后一维的数字要求必须是1.因为卷积步长只对长度和宽度有关;  
最后一个参数为填充方法，其中SAME表示添加全0填充，VAILD表示不添加。
```
conv=tf.nn.conv2(input,filter_weight,strides=[1,1,1,1],padding='SAME')
```  
tf.nn.bias_add函数可以方便的给每个节点添加偏置项。注意这里不能使用加法，因为矩阵的不同位置上都要添加同样的偏置项。

```
bias=tf.nn.bias_add(conv,biases)
```
3. 激活函数去线性化
```
actived_conv=tf.nn.relu(bias)
```
4.池化  
卷积层池化层中过滤器的移动方式是相似的，唯一的区别在于卷积层使用的过滤器是横跨整个深度的，而池化层使用的过滤器之影响一个深度节点。所以池化层的过滤器除了在长和宽两个维度上移动之外，还要在深度这个维度上移动。  
tf.nn.max_pool实现了最大池化层的前向传播过程。
```
pool=tf.nn.max_pool(actived_conv,ksize=[1,3,3,1],strides=[1,2,2,1],paddding='SAME')
```
