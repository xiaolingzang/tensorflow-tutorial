
### tensorflow 实现卷积网的基本函数
1. 通过tf.get_varibale的方式创建过滤器的权重和偏置项变量  
卷积层的参数个数只和过滤器的尺寸、深度、以及当前层节点矩阵的深度有关，所以声明的参数变量是一个四维矩阵，前面两个维度代表了过滤器的尺寸，第三个维度代表了当前层的深度，第四个维度表示过滤器的深度。
```
filter_weigth=tf.get_variable('weigth',[5,5,3,16],initializer=tf.constant_initializer(0.1))
```

    和卷积权重类似，当前层上不同位置上的偏置项也是共享的，所以共有一下层深度的不同个偏置项。


```
biases=tf.get_varibale('biases',[16],initializer=tf.constant_initializer(0.1)
```
2. 卷积过程  
tf.nn.conv2d提供了一个非常方便的函数用来实现卷积神经网络的前向传播算法.  
这个函数的第一个输入为当前层节点矩阵，这个矩阵是一个四维矩阵，后面三个维度对应一个节点矩阵，第一维对应一个输入batch；  
这个函数的第二个参数对应卷积权重；
第三个参数为不同维度上的步长。虽然第三个参数提供了一个长度为4的数组，但是第一维和最后一维的数字要求必须是1.因为卷积步长只对长度和宽度有关;  
最后一个参数为填充方法，其中SAME表示添加全0填充，VAILD表示不添加。
```
conv=tf.nn.conv2(input,filter_weight,strides=[1,1,1,1],padding='SAME')
```

    tf.nn.bias_add函数可以方便的给每个节点添加偏置项。注意这里不能使用加法，因为矩阵的不同位置上都要添加同样的偏置项。

```
bias=tf.nn.bias_add(conv,biases)
```
3. 激活函数去线性化
```
actived_conv=tf.nn.relu(bias)
```
